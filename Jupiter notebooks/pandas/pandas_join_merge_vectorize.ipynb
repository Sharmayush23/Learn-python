{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**1. Pivot Tables**\n",
    "\n",
    "*   **Concept:** Pivot tables are a powerful tool for **reshaping and summarizing data**. They allow you to transform data from a long format to a more easily readable, summarized format. Pivot tables are especially useful for multi-dimensional analysis.\n",
    "*   **Analogy**: Think of a spreadsheet where you can drag and drop columns to rearrange how the data is presented, calculating totals and averages at the same time.\n",
    "*   **Syntax**:\n",
    "    ```python\n",
    "    df.pivot_table(\n",
    "        index='column_name',\n",
    "        columns='column_name',\n",
    "        values='column_name',\n",
    "        aggfunc='function',\n",
    "        margins=True/False\n",
    "        )\n",
    "    ```\n",
    "    *   **`index='column_name'`**:  This specifies which column from your DataFrame will become the **index (rows)** of the pivot table.\n",
    "    *  **`columns='column_name'`**: This specifies which column will have its **unique values converted to columns** in the new table.\n",
    "    *   **`values='column_name'`**: This indicates which column contains the **values** that you want to aggregate or summarize.\n",
    "    *   **`aggfunc='function'`**: This is the function that will be used to aggregate the data, such as the **sum, mean, min, max, standard deviation, or count**. If not specified, the default is `mean`.\n",
    "    *   **`margins=True/False`**: When set to true, will add **extra rows and columns** to show subtotals and grand totals.\n",
    "*   **Example**:  To find the average bill for males and females in a restaurant dataset, you might use `df.pivot_table(index='sex', values='total_bill', aggfunc='mean')`. You could further specify the columns to include whether they smoke or not `df.pivot_table(index='sex', columns='smoker', values='total_bill', aggfunc='mean')`.\n",
    "*   **Key Points**:\n",
    "    *   Pivot tables can be used on categorical columns.\n",
    "    *   They can handle multi-dimensional data, summarizing it in a tabular format.\n",
    "    *   Pivot tables can also perform complex aggregations using different functions.\n",
    "    *   They can be used to perform analysis on multiple categorical columns simultaneously.\n",
    "    *   If values are not specified, pivot tables will analyze all numerical columns by default.\n",
    "\n",
    "**2. Vectorized String Operations**\n",
    "\n",
    "*   **Concept**: Vectorized string operations allow you to apply string manipulation functions to entire columns of text data **without using loops**. This is more efficient than iterating through the data. They also handle missing data (`NaN`) gracefully.\n",
    "*  **How to Access**: String operations are accessed using the `.str` attribute on a Pandas Series or DataFrame column.\n",
    "*   **Common Operations:**\n",
    "    *   **`lower()`**: Converts all characters in the string to lowercase.\n",
    "        *   Example: `df['name'].str.lower()`\n",
    "    *   **`upper()`**: Converts all characters in the string to uppercase.\n",
    "        *   Example: `df['name'].str.upper()`\n",
    "    *   **`capitalize()`**: Capitalizes the first character of each string in the column.\n",
    "        *   Example:  `df['name'].str.capitalize()`\n",
    "    *   **`title()`**: Capitalizes the first character of each word in the string.\n",
    "        *   Example: `df['name'].str.title()`\n",
    "    *   **`strip()`**: Removes leading and trailing whitespace from each string.\n",
    "        *   Example:  `df['name'].str.strip()`\n",
    "    *   **`split()`**: Splits a string into a list of substrings based on a delimiter.\n",
    "        *   **Syntax**:  `df['column_name'].str.split(delimiter, n=number_of_splits, expand=True/False)`\n",
    "            *   **`delimiter`**: The character or string used to split the text.\n",
    "            *  **`n`**: The maximum number of splits to perform.\n",
    "            *   **`expand=True`**: Returns a DataFrame with split strings in separate columns. `expand=False` returns a Series.\n",
    "        *   Example: `df['name'].str.split(' ', n=1, expand=True)`\n",
    "     *    **`get(index)`**: Extracts an element at a specific index from each list of strings.\n",
    "         * Example: `df['name'].str.split(' ').str.get(0)` will get the first element in each string in the `name` column.\n",
    "     *   **`replace(old_string, new_string)`**: Replaces occurrences of `old_string` with `new_string` in each string.\n",
    "         *   Example: `df['title'].str.replace('MS', 'Miss')`\n",
    "    *    **`contains(substring, case=True/False)`**: Checks if a string contains the specified `substring`, case-sensitive or case-insensitive.\n",
    "         *   Example: `df['name'].str.contains('John', case=False)`\n",
    "    *   **Regular Expressions with `contains()`**:  Allows for complex pattern matching.\n",
    "         * Example: `df['name'].str.contains(r'^[AEIOUaeiou].*[AEIOUaeiou]$')` finds names that start and end with vowels.\n",
    "    *   **Slicing**: Extracts a portion of each string.\n",
    "         *   Example: `df['name'].str[0:4]` gets the first four characters of each name.\n",
    "*   **Key Points**:\n",
    "    *   Vectorized operations make string manipulations fast and efficient.\n",
    "    *   They are essential for working with text data.\n",
    "    *   These operations handle missing values without errors.\n",
    "\n",
    "**3. Date and Time Operations**\n",
    "\n",
    "*   **Concept:** Pandas provides robust tools for working with time series data, including creating, manipulating, and extracting information from dates and times.\n",
    "*   **Timestamp**: A `Timestamp` object represents a specific moment in time.\n",
    "    *   **Syntax**: `pd.Timestamp('date_string')` or `pd.to_datetime('date_string')`.\n",
    "        * Example: `pd.Timestamp('2023-01-05')`\n",
    "*   **`date_range()`**: Generates a sequence of dates.\n",
    "    *   **Syntax**: `pd.date_range(start='start_date', end='end_date', freq='frequency')`\n",
    "        *   **`start`**: The start date.\n",
    "        *   **`end`**: The end date.\n",
    "        *   **`freq`**: The frequency of dates, e.g.  `D` for daily, `B` for business days, `M` for end of month,  `H` for hourly, `2D` for every two days.\n",
    "*   **`dt` accessor**: Used to access date and time components from a datetime object.\n",
    "    *   **Examples**:\n",
    "        *   `df['date_column'].dt.year` extracts the year.\n",
    "        *    `df['date_column'].dt.month` extracts the month.\n",
    "        *    `df['date_column'].dt.day` extracts the day.\n",
    "        *    `df['date_column'].dt.hour` extracts the hour.\n",
    "        *   `df['date_column'].dt.month_name()` extracts the full name of the month.\n",
    "        *   `df['date_column'].dt.quarter` extracts the quarter of the year.\n",
    "        *   `df['date_column'].dt.is_month_start` returns a boolean if it is the start of the month.\n",
    "        *   `df['date_column'].dt.is_month_end` returns a boolean if it is the end of the month.\n",
    "*   **`to_datetime()`**: Converts a column of strings to datetime objects.\n",
    "    *   **Syntax**: `pd.to_datetime(df['date_column'], errors='coerce')`\n",
    "        *   **`errors='coerce'`**:  Handles invalid date formats by setting them to `NaN`.\n",
    "*   **`DatetimeIndex`**: A specialized index to store multiple dates and use them for indexing data.\n",
    "*   **Key Points:**\n",
    "    *   Pandas `Timestamp` is built on NumPy's `datetime64`, which is fast and efficient.\n",
    "    *   Pandas date and time functionality is very useful for time series analysis.\n",
    "    *   Using the `dt` accessor lets you easily extract the desired information.\n",
    "\n",
    "**4. Multi-Index Objects**\n",
    "\n",
    "*   **Concept**: Multi-index objects allow for **hierarchical indexing** of data, enabling you to represent higher-dimensional data within Pandas Series and DataFrames.\n",
    "*   **Creation**:\n",
    "    *   Using a list of tuples to define index values.\n",
    "    *   `pd.MultiIndex.from_tuples(list_of_tuples)`.\n",
    "    *   `pd.MultiIndex.from_product([list1, list2])` for creating an index from the Cartesian product of multiple lists.\n",
    "*   **Hierarchical Structure:** Multi-index objects have levels (e.g., level 0, level 1). Each level can have its own labels.\n",
    "*   **Accessing Data**: Data can be accessed by specifying index values at each level using `.loc[]` or `.iloc[]`.\n",
    "*   **`unstack()`**: Converts a multi-index Series to a DataFrame. The innermost index becomes columns.\n",
    "*   **`stack()`**: Converts a DataFrame to a multi-index Series. The innermost column becomes the index.\n",
    "*    **Multi-indexing on Rows and Columns**:  Multi-indexing can be applied to both the rows (index) and columns.\n",
    "*    **Sorting**:  Sorting is possible on one or more index levels.\n",
    "*   **`swaplevel()`**: Swaps the levels of a multi-index.\n",
    "    *   Syntax: `df.swaplevel(i=0, j=1, axis=0)` or `df.swaplevel(i=0, j=1, axis=1)`\n",
    "        * `i` and `j` are the levels to swap and can be integers or names.\n",
    "        * `axis` specifies whether to swap the index levels (`axis=0`) or the column levels (`axis=1`).\n",
    "*  **`transpose()`**: Rotates the DataFrame, swapping rows and columns.\n",
    "     *   Syntax: `df.transpose()`\n",
    "*   **Key Points:**\n",
    "    *   Multi-index objects are crucial for representing multi-dimensional data within Pandas.\n",
    "    *   They provide a way to analyze and manipulate complex, hierarchical datasets.\n",
    "    *   `unstack()` and `stack()` are useful tools for reshaping data.\n",
    "\n",
    "**5. Long vs Wide Data Formats**\n",
    "\n",
    "*   **Concept:**\n",
    "    *   **Wide Format**: Data where each row represents a single data point, with multiple columns for different attributes.\n",
    "    *   **Long Format**: Data where each row represents a single attribute of a data point, with fewer columns and more rows.\n",
    "*   **Use Cases**:\n",
    "    *   Wide format is often obtained from databases. It is suitable for some analyses, such as creating visualizations with many categories in each row.\n",
    "    *   Long format is often obtained from data warehouses. It is generally easier for time series analysis and some kinds of statistical analysis.\n",
    "*   **`melt()` Function**: Converts data from wide format to long format.\n",
    "    *   **Syntax**:  `pd.melt(df, id_vars=['column_name_to_keep'], value_vars=['columns_to_convert'], var_name='new_variable_name', value_name='new_value_name')`\n",
    "        *   **`id_vars`**: Columns that are not unpivoted and are used to identify each data point.\n",
    "        *   **`value_vars`**: Columns that are converted into rows.\n",
    "        *   **`var_name`**: Name for the new column containing the names of the melted columns.\n",
    "        *    **`value_name`**: Name for the new column containing the values of the melted columns.\n",
    "    *   **Example**: To convert a DataFrame with columns for each year to a long format with 'year' and 'value' columns: `pd.melt(df, id_vars=['branch'], value_vars=['2020', '2021', '2022'], var_name='year', value_name='students')`\n",
    "*   **Key Points:**\n",
    "    *   Understanding the difference between long and wide format is important for data manipulation.\n",
    "    *   `melt()` is crucial for converting data from a wide to a long format, which is often needed for time series analysis and many other types of data analysis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**1. Merging, Joining, and Concatenating DataFrames**\n",
    "\n",
    "*   **Concept**: These operations combine multiple DataFrames into a single one. This is crucial for integrating data from different sources or tables.\n",
    "\n",
    "    *   **Concatenation**: Stacks DataFrames vertically or horizontally.\n",
    "        *   **Vertical Concatenation**: Appends DataFrames one after another, increasing the number of rows. This is useful for combining data from similar tables.\n",
    "            *   The `concat()` function is used for vertical stacking. The syntax is `pd.concat([df1, df2])` where `df1` and `df2` are DataFrames.\n",
    "            *   **Index Handling**: By default, `concat()` keeps the original indexes which can lead to duplicate indexes. To fix this, set `ignore_index=True` which will reset the index. The syntax is `pd.concat([df1, df2], ignore_index=True)`.\n",
    "            *   **Multi-Index**: If you want to preserve the original index while adding a new level of indexing, you can assign keys to the concatenated DataFrames. The syntax is `pd.concat([df1, df2], keys=['df1_name', 'df2_name'])`. This will create a multi-index.\n",
    "            *   **Accessing Data in Multi-Index DataFrames**: Use `.loc[]` and provide the keys and the original index for the row of interest. For example, `df.loc[('df1_name', 0)]` will return the first row of the DataFrame that was given the key `df1_name`.\n",
    "         *   **Append**: An older function that is now deprecated, should not be used.\n",
    "        *   **Horizontal Concatenation**: Combines DataFrames side by side. The syntax is `pd.concat([df1, df2], axis=1)`. The number of rows should match, otherwise `NaN` values are introduced.\n",
    "\n",
    "    *   **Joining**: Combines DataFrames based on a common column. It is similar to SQL JOIN operations.\n",
    "        *   **Inner Join**: Returns only the rows that have matching values in both DataFrames.  It returns the intersection of the rows in the tables. If a student ID exists in both a student table and a registration table, that row will be included in the results.\n",
    "             *   The syntax is `df1.merge(df2, on='common_column', how='inner')`. The `on` parameter is for the common column, and `how='inner'` specifies the join type.\n",
    "        *   **Left Join**: Returns all the rows from the left DataFrame and the matching rows from the right DataFrame. If a value is not present in the right DataFrame, `NaN` is shown for its values.\n",
    "            *   The syntax is `df1.merge(df2, on='common_column', how='left')`.\n",
    "        *   **Right Join**: Returns all rows from the right DataFrame and the matching rows from the left DataFrame. If a value is not present in the left DataFrame, `NaN` is shown for its values.\n",
    "            *   The syntax is `df1.merge(df2, on='common_column', how='right')`.\n",
    "         *   **Full Outer Join**: Returns all rows from both DataFrames. If a value is missing, `NaN` will be used.\n",
    "            *   The syntax is `df1.merge(df2, on='common_column', how='outer')`.\n",
    "        *   **Self Join**: A table is joined with itself. Used when data in the same table needs to be combined.\n",
    "            *   The syntax is `df.merge(df, left_on='left_column', right_on='right_column', how='inner')`.\n",
    "             *   For instance, to match students with their partners using a student table with both `student_id` and `partner_id` columns, use `df.merge(df, left_on='partner_id', right_on='student_id', how='inner')`.\n",
    "\n",
    "*   **Key Points**:\n",
    "    *   `concat()` is for stacking, while `merge()` is for joining based on common columns.\n",
    "    *   Different types of joins (inner, left, right, outer) handle unmatched data differently.\n",
    "    *   Understanding join types is essential for accurate data analysis.\n",
    "    *   The `merge` function is versatile and can perform a variety of table combinations.\n",
    "    *   Joins are essential when information needed for analysis is spread across multiple tables.\n",
    "\n",
    "**2. Grouping and Aggregation**\n",
    "\n",
    "*   **Concept**: Grouping involves dividing data into groups based on one or more columns, and aggregation is applying a function to each of those groups.\n",
    "*   **`groupby()` function**: Used to group rows that have the same values in a particular column.\n",
    "    *   The syntax is `df.groupby('column_name')`.\n",
    "    *   Multiple columns can also be used to group rows. The syntax is `df.groupby(['column1', 'column2'])`.\n",
    "    *   Grouping is often followed by an aggregate function.\n",
    "*   **Aggregation functions**: Functions that apply to each group to perform calculations like summing, averaging, etc.\n",
    "    *   **Examples:** `sum()`, `mean()`, `count()`, `max()`, `min()`.\n",
    "        *   For instance, `df.groupby('course_id')['price'].sum()` calculates the total price for each `course_id`.\n",
    "        *   To calculate the number of times a student enrolled in a course, use `df.groupby(['student_id', 'name'])['name'].count()`.\n",
    "        *   To calculate the total amount spent by a student, use `df.groupby(['student_id', 'name'])['price'].sum()`.\n",
    "*   **Key Points**:\n",
    "    *   Grouping enables applying aggregate functions to subgroups of a DataFrame.\n",
    "    *   It's a crucial step in summarizing and analyzing data.\n",
    "    *   Grouping and aggregation can be used to calculate various metrics like total revenue, average prices, and counts per category.\n",
    "\n",
    "**3. Set Operations**\n",
    "\n",
    "*   **Concept**: Set operations help in comparing data in different DataFrames or Series. Operations include intersection and set differences.\n",
    "    *   **Intersection**: Finds the common elements between two sets.\n",
    "        *   The syntax is `np.intersect1d(series1, series2)`.\n",
    "    *   **Set Difference**: Finds the elements that are in one set but not in the other.\n",
    "        *   The syntax is `np.setdiff1d(series1, series2)`.\n",
    "*   **Key Points:**\n",
    "    *   Set operations are useful in identifying shared and unique data points.\n",
    "    *   They help in filtering, comparing datasets, and preparing data for analysis.\n",
    "    *   For example, set operations can be used to find students who enrolled in courses in both November and December using intersections and those who never enrolled using set differences.\n",
    "\n",
    "**4. Data Analysis Examples**\n",
    "\n",
    "*   **Revenue Calculation**: Combining registration and course information to find total and monthly revenue.\n",
    "    *   Joining registration and course data by `course_id`, then using `sum()` on the `price` column.\n",
    "    *   Using `groupby()` on multi-indexed data and applying `sum()` to find the total revenue in each month.\n",
    "*   **Student Enrollment Analysis**: Finding students who enrolled in specific courses, or in both months, and those who never enrolled.\n",
    "     *   Using joins, groupings, set operations to filter students.\n",
    "     *   Calculating the percentage of students who did not enroll.\n",
    "*   **Course Analysis**: Identifying courses with no enrollment, plotting courses by revenue.\n",
    "     *   Using joins and `groupby()` to get course-wise revenue and plotting a bar chart using `.plot(kind='bar')`.\n",
    "*   **IPL Data Analysis**: Finding stadiums with the highest match-to-six ratio and identifying orange cap holders each season.\n",
    "    *   Joining matches and delivery data, grouping by stadium, and calculating the ratio of sixes to matches.\n",
    "    *   Grouping by season and batsman to get total runs, then sorting to find orange cap holders per season.\n",
    "*   **Multi-Indexing**: Using multi-indexing for data aggregation and analysis.\n",
    "    *   Using multi-indexing to preserve the original indices after concatenation.\n",
    "*   **Column Name Differences**: When joining, if column names are different in both tables, use `left_on` and `right_on`.\n",
    "*   **Alternative Merge Syntax**: Using `pd.merge()` and specifying the left and right DataFrames explicitly.\n",
    "\n",
    "**5. Key Points**\n",
    "\n",
    "*   The sources emphasize the importance of combining data from different tables to perform analyses.\n",
    "*   The examples show how various operations, such as joining, grouping, aggregation, set operations, and plotting can be combined for data analysis.\n",
    "*   The sources underscore the need to know how to use joins correctly to get the desired output.\n",
    "*   Understanding these concepts is crucial for effective data analysis and manipulation with Pandas.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
